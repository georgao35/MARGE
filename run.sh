python -m backwardlearning.main_distributed --distribute_type file --exp_name qwen2-7binst-grreinforce --model_path ckpts/qwen/Qwen2-7B-Instruct --train_ckpt_dir ckpts/qwen2 --datafile_path data/trajectories/stepdpo_queries.jsonl --shared_file_path .distributed/qwen2-7binst-grreinforce --eval_datafile_path data/trajectories/test.jsonl --restart_train_cycle --query_batch_size 2048 --query_batch_mode iteration --evaluation_trajs_num 8 --use_wandb --eval --eval_interval 1 --end 12 --dpo_train_epochs 2 --dpo_beta 0.01 --dpo_batch_size 1024 --dpo_lr 1e-6 --dpo_dataset_strategy grreinforce --dpo_method grreinforce --dpo_no_shuffle --step_based_states --update_trajs --update_trajs_interval 1 --init_trajs_regenerate --update_trajs_method preference --vllm_logdir logs/qwen2-7binst-grreinforce

python -m backwardlearning.main_distributed --distribute_type file --exp_name llama3.1-grreinforce-0111 --model_path ckpts/LLM-Research/Meta-Llama-3___1-8B-Instruct --train_ckpt_dir ckpts/llama3 --datafile_path data/trajectories/stepdpo_queries.jsonlv --shared_file_path .distributed/llama3.1-grreinforce-0111 --eval_datafile_path data/trajectories/test.jsonl --restart_train_cycle --model_type llama3 --train_script backwardlearning/trl_dpo_llama3.py --query_batch_size 2048 --dataset_max_p 1.1 --dataset_min_p 0.1 --query_batch_mode iteration --evaluation_trajs_num 8 --use_wandb --eval --eval_interval 1 --end 12 --dpo_train_epochs 4 --dpo_beta 0.01 --dpo_batch_size 2048 --dpo_lr 1e-6 --dpo_dataset_strategy grreinforce --dpo_method grreinforce --dpo_no_shuffle --init_trajs_regenerate --init_trajs_number 24 --update_trajs --update_trajs_interval 1 --update_trajs_method preference --vllm_logdir logs/llama3.1-grreinforce-0111


